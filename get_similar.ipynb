{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch==1.10.2+cpu torchvision==0.11.3+cpu torchaudio==0.10.2+cpu -f https://download.pytorch.org/whl/cpu/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from datasets.transforms import ReidTransforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ImageFolderWithPaths(ImageFolder):\n",
    "#     \"\"\"Custom dataset that includes image file paths. Extends\n",
    "#     torchvision.datasets.ImageFolder\n",
    "#     \"\"\"\n",
    "\n",
    "#     # override the __getitem__ method. this is the method that dataloader calls\n",
    "#     def __getitem__(self, index):\n",
    "#         # this is what ImageFolder normally returns \n",
    "#         original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "#         # the image file path\n",
    "#         path = self.imgs[index][0]\n",
    "#         # make a new tuple that includes original and the path\n",
    "#         tuple_with_path = (original_tuple + (path,))\n",
    "#         return tuple_with_path\n",
    "\n",
    "def make_inference_data_loader(cfg, path, dataset_class):\n",
    "    transforms_base = ReidTransforms(cfg)\n",
    "    val_transforms = transforms_base.build_transforms(is_train=False)\n",
    "    num_workers = cfg.DATALOADER.NUM_WORKERS\n",
    "    val_set = dataset_class(path, val_transforms)\n",
    "    val_loader = DataLoader(\n",
    "        val_set, batch_size=cfg.TEST.IMS_PER_BATCH, shuffle=False, num_workers=num_workers\n",
    "    )\n",
    "    return val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "IMG_EXTENSIONS = (\".jpg\", \".jpeg\", \".png\", \".ppm\", \".bmp\", \".pgm\", \".tif\", \".tiff\", \".webp\")\n",
    "\n",
    "from torchvision.datasets.folder import is_image_file\n",
    "\n",
    "def pil_loader(path: str) -> Image.Image:\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    with open(path, \"rb\") as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert(\"RGB\")\n",
    "\n",
    "    \n",
    "class ImageDataset(Dataset):\n",
    "    \"\"\"Image Person ReID Dataset\"\"\"\n",
    "\n",
    "    def __init__(self, dataset: list, transform = None, loader=pil_loader):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        self.loader = loader\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.dataset[index]\n",
    "        img = self.loader(img_path)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, '', img_path ## Hack to be consistent with ImageFolderWithPaths dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Callable, Dict, Union\n",
    "def get_all_images(path: Union[str, List[str]]) -> List[str]:\n",
    "    if os.path.isdir(path):\n",
    "        images = os.listdir(path)\n",
    "        return [os.path.join(path, item) for item in images if is_image_file(item)]\n",
    "    elif is_image_file(path):\n",
    "        return [path]\n",
    "    else:\n",
    "        raise Exception(f\"{path} is neither a path to a valid image file nor a path to folder containing images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import cfg\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args():\n",
    "    pass\n",
    "args.config_file = \"configs/320_resnet50_ibn_a.yml\"\n",
    "args.opts = [\"TEST.ONLY_TEST\", \"True\", \"GPU_IDS\", []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.config_file != \"\":\n",
    "    cfg.merge_from_file(args.config_file)\n",
    "cfg.merge_from_list(args.opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_path = 'test-images/gallery' # To test image taken from a single folder\n",
    "# test_path = 'test-images-folder'  # To test image where each pids is stored in a seperate directory\n",
    "# query_path = 'query.jpg'\n",
    "# query_path = 'rolex_query.jpg'\n",
    "query_path = 'test-query-images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images_paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-901eb02f7588>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimages_paths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'images_paths' is not defined"
     ]
    }
   ],
   "source": [
    "images_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_paths = get_all_images(query_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_loader = make_inference_data_loader(cfg, test_path, ImageFolderWithPaths)\n",
    "val_loader = make_inference_data_loader(cfg, images_paths, ImageDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', '') ('test-query-images/query.jpg', 'test-query-images/rolex_query.jpg')\n"
     ]
    }
   ],
   "source": [
    "for batch in val_loader:\n",
    "#     print(batch[0], batch[1])\n",
    "    print(batch[1], batch[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_ctl_model import CTLModel\n",
    "import pytorch_lightning as pl\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_path = 'reid_weights.pth' ### This is just Pytorch wegihts therefore it requires different handling\n",
    "# checkpoint_path = '/home/mwieczorek/centroids-reid/logs/df1_new/320_resnet50_ibn_a/train_ctl_model/version_2/auto_checkpoints/checkpoint_119.pth'\n",
    "checkpoint_path = './auto_checkpoints/checkpoint_119.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=[], unexpected_keys=['center_loss.centers', 'fc_query.weight'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or call with pretrained model\n",
    "# model = CTLModel.load_from_checkpoint(checkpoint_path, map_location=torch.device('cpu'))\n",
    "# model = CTLModel.load_from_checkpoint(checkpoint_path, map_location={'cuda': 'cpu'})\n",
    "model = CTLModel(cfg, num_classes=1)\n",
    "model.load_state_dict(state_dict=torch.load(checkpoint_path, map_location=torch.device('cpu'))['state_dict'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _inference(model, batch, normalize_with_bn=True):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data, _, filename = batch\n",
    "        _, global_feat = model.backbone(data.cuda() if torch.cuda.is_available() else data)\n",
    "        if normalize_with_bn:\n",
    "            global_feat = model.bn(global_feat)\n",
    "        return global_feat, filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = []\n",
    "paths = []\n",
    "\n",
    "for pos, x in enumerate(val_loader):\n",
    "#     if pos % print_freq == 0:\n",
    "#         log.info(f'Number of processed images: {pos*cfg.TEST.IMS_PER_BATCH}')\n",
    "    vec, path = _inference(model, x)\n",
    "    for vv, pp in zip(vec, path):\n",
    "        paths.append(pp)\n",
    "        vecs.append(vv.detach().cpu().numpy())\n",
    "\n",
    "all_vecs = np.vstack(vecs)\n",
    "paths = np.array(paths)\n",
    "all_vecs = np.array(all_vecs)\n",
    "\n",
    "#     return all_vecs, paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['test-query-images/query.jpg', 'test-query-images/rolex_query.jpg'],\n",
       "      dtype='<U33')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2048)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_vecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "LOAD_PATH = Path('gallery-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_gallery = torch.from_numpy(np.load(LOAD_PATH / 'embeddings.npy', allow_pickle=True))\n",
    "paths_gallery = np.load(LOAD_PATH / 'paths.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_features = True\n",
    "if normalize_features:\n",
    "    embeddings_gallery = torch.nn.functional.normalize(embeddings_gallery, dim=1, p=2)\n",
    "    all_vecs = torch.nn.functional.normalize(torch.from_numpy(all_vecs), dim=1, p=2)\n",
    "else:\n",
    "    all_vecs = torch.from_numpy(all_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = False\n",
    "device = torch.device('cuda') if use_cuda else torch.device('cpu')\n",
    "embeddings_gallery = embeddings_gallery.to(device)\n",
    "all_vecs = all_vecs.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.reid_metric import get_dist_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cosine as distance function during evaluation\n"
     ]
    }
   ],
   "source": [
    "# dist_func = get_dist_func(cfg.SOLVER.DISTANCE_FUNC)\n",
    "dist_func = get_dist_func('cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "distmat = dist_func(x=all_vecs, y=embeddings_gallery).cpu().numpy()\n",
    "indices = np.argsort(distmat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0135438 , 0.9371855 , 0.9554886 , 0.9233496 , 0.9608762 ,\n",
       "        0.8070517 , 0.89708567, 0.75736654, 0.8523031 , 0.7931752 ],\n",
       "       [0.8596092 , 0.75821984, 1.0694846 , 1.1070676 , 1.0446938 ,\n",
       "        1.0283605 , 0.95984876, 1.032609  , 0.9873477 , 0.9749332 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 9, 5, 8, 6, 3, 1, 2, 4, 0],\n",
       "       [1, 0, 6, 9, 8, 5, 7, 4, 2, 3]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(all_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['test-images-folder/wc2120102spa-027/wc2120102spa-027_06.jpg',\n",
       "        'test-images-folder/wc2121101spa-021/wc2121101spa-021_06.jpg',\n",
       "        'test-images-folder/wc2120102spa-027/wc2120102spa-027_04.jpg'],\n",
       "       ['test-images-folder/rolex/rolex_gallery.jpg',\n",
       "        'test-images-folder/apple_watch/apple_watch_gallery.jpg',\n",
       "        'test-images-folder/wc2120102spa-027/wc2120102spa-027_05.jpg']],\n",
       "      dtype='<U59')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths_gallery[indices][:, :topk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['test-query-images/query.jpg', 'test-query-images/rolex_query.jpg'],\n",
       "      dtype='<U33')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_top = indices[:, :topk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = {\n",
    "    query_path: {\n",
    "        \"indices\": indices_top[q_num, :],\n",
    "        \"paths\": paths_gallery[indices_top[q_num, :]],\n",
    "        \"distances\": distmat[q_num, indices_top[q_num, :]]\n",
    "    }\n",
    "    for q_num, query_path in enumerate(paths)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test-query-images/query.jpg': {'indices': array([7, 9, 5]),\n",
       "  'paths': array(['test-images-folder/wc2120102spa-027/wc2120102spa-027_06.jpg',\n",
       "         'test-images-folder/wc2121101spa-021/wc2121101spa-021_06.jpg',\n",
       "         'test-images-folder/wc2120102spa-027/wc2120102spa-027_04.jpg'],\n",
       "        dtype='<U59'),\n",
       "  'distances': array([0.75736654, 0.7931752 , 0.8070517 ], dtype=float32)},\n",
       " 'test-query-images/rolex_query.jpg': {'indices': array([1, 0, 6]),\n",
       "  'paths': array(['test-images-folder/rolex/rolex_gallery.jpg',\n",
       "         'test-images-folder/apple_watch/apple_watch_gallery.jpg',\n",
       "         'test-images-folder/wc2120102spa-027/wc2120102spa-027_05.jpg'],\n",
       "        dtype='<U59'),\n",
       "  'distances': array([0.75821984, 0.8596092 , 0.95984876], dtype=float32)}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = {\n",
    "    query_path: {\n",
    "        \"indices\": indices[q_num, :],\n",
    "        \"paths\": paths_gallery[indices[q_num, :]],\n",
    "        \"distances\": distmat[q_num, indices[q_num, :]]\n",
    "    }\n",
    "    for q_num, query_path in enumerate(paths)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test-query-images/query.jpg': {'indices': array([7, 9, 5, 8, 6, 3, 1, 2, 4, 0]),\n",
       "  'paths': array(['test-images-folder/wc2120102spa-027/wc2120102spa-027_06.jpg',\n",
       "         'test-images-folder/wc2121101spa-021/wc2121101spa-021_06.jpg',\n",
       "         'test-images-folder/wc2120102spa-027/wc2120102spa-027_04.jpg',\n",
       "         'test-images-folder/wc2121101spa-021/wc2121101spa-021_04.jpg',\n",
       "         'test-images-folder/wc2120102spa-027/wc2120102spa-027_05.jpg',\n",
       "         'test-images-folder/wc2120102evb-011/wc2120102evb-011_05.jpg',\n",
       "         'test-images-folder/rolex/rolex_gallery.jpg',\n",
       "         'test-images-folder/wc2120102evb-011/wc2120102evb-011_04.jpg',\n",
       "         'test-images-folder/wc2120102evb-011/wc2120102evb-011_07.jpg',\n",
       "         'test-images-folder/apple_watch/apple_watch_gallery.jpg'],\n",
       "        dtype='<U59'),\n",
       "  'distances': array([0.75736654, 0.7931752 , 0.8070517 , 0.8523031 , 0.89708567,\n",
       "         0.9233496 , 0.9371855 , 0.9554886 , 0.9608762 , 1.0135438 ],\n",
       "        dtype=float32)},\n",
       " 'test-query-images/rolex_query.jpg': {'indices': array([1, 0, 6, 9, 8, 5, 7, 4, 2, 3]),\n",
       "  'paths': array(['test-images-folder/rolex/rolex_gallery.jpg',\n",
       "         'test-images-folder/apple_watch/apple_watch_gallery.jpg',\n",
       "         'test-images-folder/wc2120102spa-027/wc2120102spa-027_05.jpg',\n",
       "         'test-images-folder/wc2121101spa-021/wc2121101spa-021_06.jpg',\n",
       "         'test-images-folder/wc2121101spa-021/wc2121101spa-021_04.jpg',\n",
       "         'test-images-folder/wc2120102spa-027/wc2120102spa-027_04.jpg',\n",
       "         'test-images-folder/wc2120102spa-027/wc2120102spa-027_06.jpg',\n",
       "         'test-images-folder/wc2120102evb-011/wc2120102evb-011_07.jpg',\n",
       "         'test-images-folder/wc2120102evb-011/wc2120102evb-011_04.jpg',\n",
       "         'test-images-folder/wc2120102evb-011/wc2120102evb-011_05.jpg'],\n",
       "        dtype='<U59'),\n",
       "  'distances': array([0.75821984, 0.8596092 , 0.95984876, 0.9749332 , 0.9873477 ,\n",
       "         1.0283605 , 1.032609  , 1.0446938 , 1.0694846 , 1.1070676 ],\n",
       "        dtype=float32)}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = Path('./results.npy')\n",
    "np.save(SAVE_PATH, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test-query-images/query.jpg': {'indices': array([7, 9, 5, 8, 6, 3, 1, 2, 4, 0]),\n",
       "  'paths': array(['test-images-folder/wc2120102spa-027/wc2120102spa-027_06.jpg',\n",
       "         'test-images-folder/wc2121101spa-021/wc2121101spa-021_06.jpg',\n",
       "         'test-images-folder/wc2120102spa-027/wc2120102spa-027_04.jpg',\n",
       "         'test-images-folder/wc2121101spa-021/wc2121101spa-021_04.jpg',\n",
       "         'test-images-folder/wc2120102spa-027/wc2120102spa-027_05.jpg',\n",
       "         'test-images-folder/wc2120102evb-011/wc2120102evb-011_05.jpg',\n",
       "         'test-images-folder/rolex/rolex_gallery.jpg',\n",
       "         'test-images-folder/wc2120102evb-011/wc2120102evb-011_04.jpg',\n",
       "         'test-images-folder/wc2120102evb-011/wc2120102evb-011_07.jpg',\n",
       "         'test-images-folder/apple_watch/apple_watch_gallery.jpg'],\n",
       "        dtype='<U59'),\n",
       "  'distances': array([0.75736654, 0.7931752 , 0.8070517 , 0.8523031 , 0.89708567,\n",
       "         0.9233496 , 0.9371855 , 0.9554886 , 0.9608762 , 1.0135438 ],\n",
       "        dtype=float32)},\n",
       " 'test-query-images/rolex_query.jpg': {'indices': array([1, 0, 6, 9, 8, 5, 7, 4, 2, 3]),\n",
       "  'paths': array(['test-images-folder/rolex/rolex_gallery.jpg',\n",
       "         'test-images-folder/apple_watch/apple_watch_gallery.jpg',\n",
       "         'test-images-folder/wc2120102spa-027/wc2120102spa-027_05.jpg',\n",
       "         'test-images-folder/wc2121101spa-021/wc2121101spa-021_06.jpg',\n",
       "         'test-images-folder/wc2121101spa-021/wc2121101spa-021_04.jpg',\n",
       "         'test-images-folder/wc2120102spa-027/wc2120102spa-027_04.jpg',\n",
       "         'test-images-folder/wc2120102spa-027/wc2120102spa-027_06.jpg',\n",
       "         'test-images-folder/wc2120102evb-011/wc2120102evb-011_07.jpg',\n",
       "         'test-images-folder/wc2120102evb-011/wc2120102evb-011_04.jpg',\n",
       "         'test-images-folder/wc2120102evb-011/wc2120102evb-011_05.jpg'],\n",
       "        dtype='<U59'),\n",
       "  'distances': array([0.75821984, 0.8596092 , 0.95984876, 0.9749332 , 0.9873477 ,\n",
       "         1.0283605 , 1.032609  , 1.0446938 , 1.0694846 , 1.1070676 ],\n",
       "        dtype=float32)}}"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:alpr]",
   "language": "python",
   "name": "conda-env-alpr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
